{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7daece6",
   "metadata": {},
   "source": [
    "### PART 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093c2ccc",
   "metadata": {},
   "source": [
    "#### Interesting to test and compare 3 to 4 different non linear models (maybe testing more but only 3 to 4 in the report), try to not have 3 models of the same 'family' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884e8a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.inspection import permutation_importance \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc579572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(y_pred, y_true):\n",
    "    return root_mean_squared_error(y_true, y_pred)\n",
    "\n",
    "def optimize_model(model, params, X_train, y_train, scoring_metric='neg_root_mean_squared_error'):\n",
    "    \"\"\"\n",
    "    Optimise les hyperparamètres du modèle en utilisant GridSearchCV.\n",
    "    \"\"\"\n",
    "    # GridSearchCV utilise la validation croisée (CV) pour trouver la meilleure combinaison de paramètres\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=params,\n",
    "        scoring=scoring_metric,\n",
    "        cv=5, # 5-fold cross-validation\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Entraînement et optimisation\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Affichage des meilleurs résultats\n",
    "    best_score = -grid_search.best_score_ # Le score est négatif car nous maximisons un score d'erreur\n",
    "    print(f\"Meilleurs paramètres trouvés: {grid_search.best_params_}\")\n",
    "    print(f\"RMSE de Cross-Validation (Moyenne): {best_score:.4f}\")\n",
    "    \n",
    "    return grid_search.best_estimator_, best_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b38cb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Optimisation du Random Forest ---\")\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [5, 10, None], # None = expande jusqu'à ce que les feuilles soient pures\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "best_rf_model, cv_rmse_rf = optimize_model(RandomForestRegressor(random_state=42), \n",
    "                                          rf_params, \n",
    "                                          X_train_full_scaled_df, \n",
    "                                          y_train_full)\n",
    "rf_test_pred = best_rf_model.predict(X_test_scaled_df)\n",
    "rmse_test_rf = compute_rmse(rf_test_pred, y_test)\n",
    "print(f\"Random Forest RMSE sur le jeu de TEST: {rmse_test_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dcc7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Optimisation du K-NN ---\")\n",
    "knn_params = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'], # Poids uniformes ou pondérés par l'inverse de la distance\n",
    "    'p': [1, 2] # 1 pour distance de Manhattan, 2 pour distance Euclidienne\n",
    "}\n",
    "\n",
    "best_knn_model, cv_rmse_knn = optimize_model(KNeighborsRegressor(), \n",
    "                                            knn_params, \n",
    "                                            X_train_full_scaled_df, \n",
    "                                            y_train_full)\n",
    "knn_test_pred = best_knn_model.predict(X_test_scaled_df)\n",
    "rmse_test_knn = compute_rmse(knn_test_pred, y_test)\n",
    "print(f\"K-NN RMSE sur le jeu de TEST: {rmse_test_knn:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b489b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Optimisation du SVR ---\")\n",
    "svr_params = {\n",
    "    'C': [0.1, 1, 10], # Paramètre de régularisation\n",
    "    'gamma': ['scale', 'auto'], # Coefficient du noyau (kernel)\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "best_svr_model, cv_rmse_svr = optimize_model(SVR(), \n",
    "                                           svr_params, \n",
    "                                           X_train_full_scaled_df, \n",
    "                                           y_train_full)\n",
    "svr_test_pred = best_svr_model.predict(X_test_scaled_df)\n",
    "rmse_test_svr = compute_rmse(svr_test_pred, y_test)\n",
    "print(f\"SVR RMSE sur le jeu de TEST: {rmse_test_svr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3c3d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Optimisation du MLP (Simple) ---\")\n",
    "mlp_params = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 25)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': [0.0001, 0.001], # Terme de régularisation L2\n",
    "    'max_iter': [300]\n",
    "}\n",
    "\n",
    "# Le MLP peut nécessiter une mise à l'échelle (déjà fait ici) et est très sensible aux initialisations.\n",
    "best_mlp_model, cv_rmse_mlp = optimize_model(MLPRegressor(random_state=42), \n",
    "                                           mlp_params, \n",
    "                                           X_train_full_scaled_df, \n",
    "                                           y_train_full)\n",
    "mlp_test_pred = best_mlp_model.predict(X_test_scaled_df)\n",
    "rmse_test_mlp = compute_rmse(mlp_test_pred, y_test)\n",
    "print(f\"MLP RMSE sur le jeu de TEST: {rmse_test_mlp:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c32aa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rassembler les résultats des meilleurs modèles\n",
    "results = {\n",
    "    \"Random Forest\": {'model': best_rf_model, 'rmse': rmse_test_rf},\n",
    "    \"K-NN\": {'model': best_knn_model, 'rmse': rmse_test_knn},\n",
    "    \"SVR\": {'model': best_svr_model, 'rmse': rmse_test_svr},\n",
    "    \"MLP\": {'model': best_mlp_model, 'rmse': rmse_test_mlp},\n",
    "}\n",
    "\n",
    "# Trouver le meilleur modèle\n",
    "best_model_name = min(results, key=lambda k: results[k]['rmse'])\n",
    "best_model = results[best_model_name]['model']\n",
    "\n",
    "print(f\"\\n=======================================================\")\n",
    "print(f\"Le meilleur modèle non linéaire global est: {best_model_name} avec RMSE = {results[best_model_name]['rmse']:.4f}\")\n",
    "print(f\"=======================================================\")\n",
    "\n",
    "# --- ANALYSE D'IMPORTANCE PAR PERMUTATION ---\n",
    "# Appliquée au meilleur modèle global\n",
    "print(f\"\\n--- Importance par Permutation pour le meilleur modèle: {best_model_name} ---\")\n",
    "\n",
    "result = permutation_importance(\n",
    "    best_model, \n",
    "    X_test_scaled_df, \n",
    "    y_test, \n",
    "    n_repeats=30, # Augmenter les répétitions pour plus de stabilité\n",
    "    random_state=42, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Créer un DataFrame pour la visualisation\n",
    "sorted_idx = result.importances_mean.argsort()[::-1]\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_test_scaled_df.columns[sorted_idx],\n",
    "    'Importance_Mean': result.importances_mean[sorted_idx],\n",
    "    'Importance_Std': result.importances_std[sorted_idx]\n",
    "})\n",
    "\n",
    "print(feature_importance_df)\n",
    "\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
